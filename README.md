# Learning_Labs-2-Decision-Tree-R-Code

## Decision trees are mainly classification and regression types.

- Classification means Y variable is factor and regression type means Y variable is numeric. Just look at one of the examples from each type,

- Classification example is detecting email spam data and regression tree example is from Boston housing data.

## Decision trees are also called Trees and CART.

- CART indicates classification and regression trees.

- The main goal behind the classification tree is to classify or predict an outcome based on a set of predictors.


## Advantageous of Decision Trees
- Easy Interpretation

- Making predictions is fast

- Easy to identify important variables

- Handless missing data

- One of the drawbacks is to can have high variability in performance.

- Recursive portioning- basis can achieve maximum homogeneity within the new partition.
